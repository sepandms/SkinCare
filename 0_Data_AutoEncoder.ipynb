{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "#import torchvision.transforms.Compose\n",
    "import numpy as np\n",
    "from datetime import datetime\t\n",
    "import random\n",
    "import os\n",
    "import PIL as pl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle as pickle\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else \"cpu\")\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path = '/Users/sepehrbe/DataSources/Kaggle/SkinCare/Data/Pickle_Data/'\n",
    "p_models = '/Users/sepehrbe/DataSources/Kaggle/SkinCare/Models/Saved/'\n",
    "G_path = '/Users/sepehrbe/Google_Drive/DataSources/SkinCare/Augmented_AutoEncoded/'\n",
    "G_save = '/Users/sepehrbe/Google_Drive/DataSources/SkinCare/Saved/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Meta Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'HAM10000_metadata_augmented.csv'\n",
    "meta_data_v0 = pd.read_csv(G_path + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>HAM_0002761</td>\n",
       "      <td>ISIC_0029176</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191</th>\n",
       "      <td>8191</td>\n",
       "      <td>10732</td>\n",
       "      <td>AUG_HAM_0005270</td>\n",
       "      <td>AUG_ISIC_0032270</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>8192</td>\n",
       "      <td>10733</td>\n",
       "      <td>AUG_HAM_0006193</td>\n",
       "      <td>AUG_ISIC_0029877</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>8193</td>\n",
       "      <td>10734</td>\n",
       "      <td>AUG_HAM_0003862</td>\n",
       "      <td>AUG_ISIC_0033031</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>8194</td>\n",
       "      <td>10735</td>\n",
       "      <td>AUG_HAM_0006889</td>\n",
       "      <td>AUG_ISIC_0031197</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8195</th>\n",
       "      <td>8195</td>\n",
       "      <td>10736</td>\n",
       "      <td>AUG_HAM_0001920</td>\n",
       "      <td>AUG_ISIC_0029486</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8196 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index        lesion_id          image_id   dx  dx_type  \\\n",
       "0              0      0      HAM_0000118      ISIC_0027419  2.0      3.0   \n",
       "1              1      2      HAM_0002730      ISIC_0026769  2.0      3.0   \n",
       "2              2      4      HAM_0001466      ISIC_0031633  2.0      3.0   \n",
       "3              3      6      HAM_0002761      ISIC_0029176  2.0      3.0   \n",
       "4              4      8      HAM_0005132      ISIC_0025837  2.0      3.0   \n",
       "...          ...    ...              ...               ...  ...      ...   \n",
       "8191        8191  10732  AUG_HAM_0005270  AUG_ISIC_0032270  6.0      3.0   \n",
       "8192        8192  10733  AUG_HAM_0006193  AUG_ISIC_0029877  6.0      1.0   \n",
       "8193        8193  10734  AUG_HAM_0003862  AUG_ISIC_0033031  6.0      3.0   \n",
       "8194        8194  10735  AUG_HAM_0006889  AUG_ISIC_0031197  6.0      3.0   \n",
       "8195        8195  10736  AUG_HAM_0001920  AUG_ISIC_0029486  6.0      3.0   \n",
       "\n",
       "       age  sex  localization  \n",
       "0     80.0  1.0          11.0  \n",
       "1     80.0  1.0          11.0  \n",
       "2     75.0  1.0           4.0  \n",
       "3     60.0  1.0           5.0  \n",
       "4     70.0  0.0           2.0  \n",
       "...    ...  ...           ...  \n",
       "8191  70.0  0.0           9.0  \n",
       "8192  80.0  1.0           9.0  \n",
       "8193  45.0  1.0          14.0  \n",
       "8194  20.0  1.0          14.0  \n",
       "8195  55.0  1.0           2.0  \n",
       "\n",
       "[8196 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "training_set = torchvision.datasets.ImageFolder(root = G_path + \"latent_dataset_train_valid_test20/Training_set\", transform = transforms.ToTensor())\n",
    "validation_set = torchvision.datasets.ImageFolder(root = G_path + \"latent_dataset_train_valid_test20/Validation_set\", transform = transforms.ToTensor())\n",
    "test_set = torchvision.datasets.ImageFolder(root = G_path + \"latent_dataset_train_valid_test20/Test_set\", transform = transforms.ToTensor())\n",
    "\n",
    "loader = DataLoader(dataset = training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6556/6556 [00:09<00:00, 688.18it/s]\n",
      "100%|██████████| 820/820 [00:01<00:00, 697.53it/s]\n",
      "100%|██████████| 820/820 [00:01<00:00, 698.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def import_imges(img_path):\n",
    "    img_list = []\n",
    "    for path, dirs, files in  os.walk(img_path):\n",
    "        for f in files:\n",
    "            img_list.append( path +'/' + f)\n",
    "        for d in dirs:\n",
    "            img_list.append( path + d)\n",
    "    img_list = list(set([x for x in img_list if \".jpg\" in x] ))\n",
    "\n",
    "    dataset = pd.DataFrame(columns=['image_id','img_array'])\n",
    "    for img in tqdm(img_list):\n",
    "        img_name = re.findall('\\w+', img)[-2:-1][0]\n",
    "        image = pl.Image.open( img)\n",
    "        img_array = np.asarray(image)\n",
    "        new_row = pd.Series({'image_id':img_name,'img_array':img_array}, name='')\n",
    "        dataset = dataset.append(new_row)\n",
    "    return dataset\n",
    "\n",
    "train_path = G_path + 'latent_dataset_train_valid_test20/Training_set'\n",
    "valid_path = G_path + 'latent_dataset_train_valid_test20/Validation_set'\n",
    "test_path = G_path + 'latent_dataset_train_valid_test20/Test_set'\n",
    "\n",
    "trainin_set = import_imges(train_path)\n",
    "valid_set = import_imges(valid_path)\n",
    "test_set = import_imges(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainin_set['type'] = 'train'\n",
    "valid_set['type'] = 'valid'\n",
    "test_set['type'] = 'test'\n",
    "dataset_ = pd.concat([trainin_set,valid_set,test_set],axis=0)\n",
    "\n",
    "data = dataset_.merge(meta_data_v0, how=\"left\",on='image_id').rename(columns={'dx':'image_label'})\n",
    "\n",
    "class_5 = data[data.image_label==5]\n",
    "class_5_reduced = class_5.sample(n=2800, random_state=0)\n",
    "data_blc = pd.concat([data[data.image_label!=5],class_5_reduced],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  4483  Valid Size:  556  Test size:  554\n"
     ]
    }
   ],
   "source": [
    "df_ = data_blc\n",
    "train_data = df_[df_.type=='train']\n",
    "valid_data = df_[df_.type=='valid']\n",
    "test_data = df_[df_.type=='test']\n",
    "training_data = pd.concat([train_data,valid_data], axis=0)\n",
    "print('Train size: ',train_data.shape[0] ,' Valid Size: ',valid_data.shape[0], ' Test size: ', test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : [0.40844554 0.15622149 0.23501862]   STD: [0.23811592 0.22666917 0.16962418]\n"
     ]
    }
   ],
   "source": [
    "training_arrays_scaled = np.stack(training_data['img_array'].values)  / 255\n",
    "Mean = training_arrays_scaled.mean(axis = (0,1,2)) \n",
    "STD = training_arrays_scaled.std(axis = (0,1,2))\n",
    "print(f\"Mean : {Mean}   STD: {STD}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data standardization\n",
    "train_arrays_std = np.stack(train_data['img_array'].values) / 255\n",
    "for i in range(0,train_arrays_std.shape[0]):\n",
    "    train_arrays_std[i] = (train_arrays_std[i] - Mean) / STD\n",
    "#Validation data standardization\n",
    "valid_arrays_std = np.stack(valid_data['img_array'].values) / 255\n",
    "for i in range(0,valid_arrays_std.shape[0]):\n",
    "    valid_arrays_std[i] = (valid_arrays_std[i] - Mean) / STD\n",
    "#Test data standardization\n",
    "test_arrays_std = np.stack(test_data['img_array'].values) / 255\n",
    "for i in range(0,test_arrays_std.shape[0]):\n",
    "    test_arrays_std[i] = (test_arrays_std[i] - Mean) / STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : [ 0.00251487 -0.00027692 -0.00313081]   STD: [1.00323344 1.00273593 0.99918996]\n"
     ]
    }
   ],
   "source": [
    "Mean_t = train_arrays_std.mean(axis = (0,1,2)) \n",
    "STD_t = train_arrays_std.std(axis = (0,1,2))\n",
    "print(f\"Mean : {Mean_t}   STD: {STD_t}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : [ 0.00062381 -0.02893157 -0.00206642]   STD: [0.98936703 0.94563095 0.9829966 ]\n"
     ]
    }
   ],
   "source": [
    "Mean_t = test_arrays_std.mean(axis = (0,1,2)) \n",
    "STD_t = test_arrays_std.std(axis = (0,1,2))\n",
    "print(f\"Mean : {Mean_t}   STD: {STD_t}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays_std_T = torch.tensor(train_arrays_std, dtype= torch.float32).transpose(3,1)\n",
    "train_labels = torch.tensor(train_data['image_label'].values.astype(np.long))\n",
    "\n",
    "valid_arrays_std_T = torch.tensor(valid_arrays_std, dtype= torch.float32).transpose(3,1)\n",
    "valid_labels = torch.tensor(valid_data['image_label'].values.astype(np.long))\n",
    "\n",
    "test_arrays_std_T = torch.tensor(test_arrays_std, dtype= torch.float32).transpose(3,1)\n",
    "test_labels = torch.tensor(test_data['image_label'].values.astype(np.long))\n",
    "\n",
    "input_data = (train_arrays_std_T , valid_arrays_std_T, test_arrays_std_T )\n",
    "labels = (train_labels,valid_labels,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(input_data, open(G_path + 'AutoEncoder_input_data_blc', 'wb'))\n",
    "pickle.dump(labels, open(G_path + 'AutoEncoder_labels_blc', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Filling NaN/Unkown Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data_v0.copy()\n",
    "meta_data['age'].fillna(meta_data.groupby('sex')['age'].transform('mean'),inplace=True)\n",
    "meta_data['sex'].replace('unknown',np.nan, inplace=True)\n",
    "meta_data['sex'].fillna(meta_data.groupby('dx')['sex'].value_counts().index[0][1],inplace=True)\n",
    "\n",
    "meta_data['localization'].replace('unknown',np.nan, inplace=True)\n",
    "meta_data['localization'].fillna(meta_data.groupby(['dx','sex'])['localization'].value_counts().index[0][2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########    lesion_id      #########################\n",
      "HAM_0003789    6\n",
      "HAM_0000835    6\n",
      "HAM_0005263    6\n",
      "HAM_0001863    6\n",
      "HAM_0007427    5\n",
      "              ..\n",
      "HAM_0006000    1\n",
      "HAM_0002762    1\n",
      "HAM_0006894    1\n",
      "HAM_0007132    1\n",
      "HAM_0003347    1\n",
      "Name: lesion_id, Length: 7470, dtype: int64\n",
      "####################################################\n",
      "#########    image_id      #########################\n",
      "ISIC_0027419    1\n",
      "ISIC_0030646    1\n",
      "ISIC_0030164    1\n",
      "ISIC_0032069    1\n",
      "ISIC_0029007    1\n",
      "               ..\n",
      "ISIC_0028768    1\n",
      "ISIC_0026383    1\n",
      "ISIC_0025794    1\n",
      "ISIC_0028888    1\n",
      "ISIC_0032258    1\n",
      "Name: image_id, Length: 10015, dtype: int64\n",
      "####################################################\n",
      "#########    dx      #########################\n",
      "nv       6705\n",
      "mel      1113\n",
      "bkl      1099\n",
      "bcc       514\n",
      "akiec     327\n",
      "vasc      142\n",
      "df        115\n",
      "Name: dx, dtype: int64\n",
      "####################################################\n",
      "#########    dx_type      #########################\n",
      "histo        5340\n",
      "follow_up    3704\n",
      "consensus     902\n",
      "confocal       69\n",
      "Name: dx_type, dtype: int64\n",
      "####################################################\n",
      "#########    age      #########################\n",
      "45.000000    1299\n",
      "50.000000    1187\n",
      "55.000000    1009\n",
      "40.000000     985\n",
      "60.000000     803\n",
      "70.000000     756\n",
      "35.000000     753\n",
      "65.000000     731\n",
      "75.000000     618\n",
      "30.000000     464\n",
      "80.000000     404\n",
      "85.000000     290\n",
      "25.000000     247\n",
      "20.000000     169\n",
      "5.000000       86\n",
      "15.000000      77\n",
      "37.500000      47\n",
      "10.000000      41\n",
      "0.000000       39\n",
      "54.545370       6\n",
      "48.711522       4\n",
      "Name: age, dtype: int64\n",
      "####################################################\n",
      "#########    sex      #########################\n",
      "male      5463\n",
      "female    4552\n",
      "Name: sex, dtype: int64\n",
      "####################################################\n",
      "#########    localization      #########################\n",
      "back               2192\n",
      "lower extremity    2077\n",
      "trunk              1404\n",
      "upper extremity    1118\n",
      "abdomen            1022\n",
      "face                979\n",
      "chest               407\n",
      "foot                319\n",
      "neck                168\n",
      "scalp               128\n",
      "hand                 90\n",
      "ear                  56\n",
      "genital              48\n",
      "acral                 7\n",
      "Name: localization, dtype: int64\n",
      "####################################################\n"
     ]
    }
   ],
   "source": [
    "for s in meta_data.columns:\n",
    "    print('#########   ', s , '     #########################')\n",
    "    print(meta_data[s].value_counts( dropna = False ))\n",
    "    print('####################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = os.listdir(img_path)\n",
    "HAM_DataSource = pd.DataFrame(columns=['image_id','img_array'])\n",
    "for img in img_list:\n",
    "    img_name = img.replace('.jpg','')\n",
    "    image = pl.Image.open( img_path + img)\n",
    "    img_array = np.asarray(image)\n",
    "    new_row = pd.Series({'image_id':img_name,'img_array':img_array}, name='')\n",
    "    HAM_DataSource = HAM_DataSource.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DataSource = HAM_DataSource.merge(meta_data, how=\"left\",on='image_id').rename(columns={'dx':'image_label'})\n",
    "HAM_DataSource.image_label = pd.Categorical(HAM_DataSource.image_label)\n",
    "HAM_DataSource['label_id'] = HAM_DataSource.image_label.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Balance DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class1 = resample(HAM_DataSource[HAM_DataSource.label_id==5], replace=True,   n_samples=1200, random_state=0) \n",
    "df_other_classes = HAM_DataSource[HAM_DataSource.label_id!=5]\n",
    "HAM_DataSource_blc = pd.concat([df_other_classes,df_class1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1200\n",
       "4    1113\n",
       "2    1099\n",
       "1     514\n",
       "0     327\n",
       "6     142\n",
       "3     115\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM_DataSource_blc.label_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Remove Duplications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DataSource_blc_noDup = HAM_DataSource_blc.groupby('lesion_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1039\n",
       "2     727\n",
       "4     614\n",
       "1     327\n",
       "0     228\n",
       "6      98\n",
       "3      73\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM_DataSource_blc_noDup.label_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3106 entries, 0 to 3105\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   lesion_id     3106 non-null   object  \n",
      " 1   image_id      3106 non-null   object  \n",
      " 2   img_array     3106 non-null   object  \n",
      " 3   image_label   3106 non-null   category\n",
      " 4   dx_type       3106 non-null   object  \n",
      " 5   age           3106 non-null   float64 \n",
      " 6   sex           3106 non-null   object  \n",
      " 7   localization  3106 non-null   object  \n",
      " 8   label_id      3106 non-null   int8    \n",
      "dtypes: category(1), float64(1), int8(1), object(6)\n",
      "memory usage: 176.4+ KB\n"
     ]
    }
   ],
   "source": [
    "HAM_DataSource_blc_noDup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ = HAM_DataSource_blc_noDup\n",
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x='image_label', data=df_, hue='sex')\n",
    "# ax.set_ylim(0,500)\n",
    "plt.title(\"Impact of sex on Skin Lesion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, tst_ratio, valid_ratio):\n",
    "    training_data, test_data = train_test_split(dataset, test_size = tst_ratio, random_state=0,stratify=dataset['label_id'])\n",
    "    train_data, valid_data = train_test_split(training_data, test_size= valid_ratio, random_state=0,stratify=training_data['label_id'])\n",
    "    train_data['type'] = 'train'\n",
    "    valid_data['type'] = 'valid'\n",
    "    test_data['type'] = 'test'\n",
    "    dataset = pd.concat([train_data,valid_data,test_data],axis=0)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Split DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DataSource_blc = split_dataset(dataset = HAM_DataSource_blc , tst_ratio = 0.1, valid_ratio  = 0.1)\n",
    "HAM_DataSource_blc_noDup = split_dataset(dataset = HAM_DataSource_blc_noDup , tst_ratio = 0.1, valid_ratio  = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.266083\n",
       "4    0.246920\n",
       "2    0.243635\n",
       "1    0.114153\n",
       "0    0.072269\n",
       "6    0.031481\n",
       "3    0.025459\n",
       "Name: label_id, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM_DataSource_blc[HAM_DataSource_blc.type=='train'].label_id.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.266075\n",
       "4    0.246120\n",
       "2    0.243902\n",
       "1    0.113082\n",
       "0    0.073171\n",
       "6    0.031042\n",
       "3    0.026608\n",
       "Name: label_id, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM_DataSource_blc[HAM_DataSource_blc.type=='test'].label_id.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Standardization / Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizaion(dataset, attr):\n",
    "    mean = dataset[dataset.type.str.contains('train|valid')][attr].mean()\n",
    "    std = dataset[dataset.type.str.contains('train|valid')][attr].std()\n",
    "    dataset[attr] = (dataset[attr] - mean ) / std\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaling(dataset, attr):\n",
    "    min = dataset[dataset.type.str.contains('train|valid')][attr].min()\n",
    "    max = dataset[dataset.type.str.contains('train|valid')][attr].max()\n",
    "    dataset[attr] = (dataset[attr] - min ) / (max-min)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAM_DataSource_blc_STD = standardizaion(HAM_DataSource_blc , 'age')\n",
    "# HAM_DataSource_blc_noDup_STD = standardizaion(HAM_DataSource_blc_noDup , 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DataSource_blc_STD = MinMaxScaling(HAM_DataSource_blc , 'age')\n",
    "HAM_DataSource_blc_noDup_STD = MinMaxScaling(HAM_DataSource_blc_noDup , 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640    0.823529\n",
       "6104    0.470588\n",
       "8607    0.529412\n",
       "9745    1.000000\n",
       "2110    0.882353\n",
       "          ...   \n",
       "6008    0.647059\n",
       "8295    0.529412\n",
       "30      0.823529\n",
       "8189    0.470588\n",
       "2600    0.647059\n",
       "Name: age, Length: 4510, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM_DataSource_blc_STD['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(HAM_DataSource_blc_STD,G_path + 'DataSource_60x45_Red')\n",
    "# pd.to_pickle(HAM_DataSource_blc_noDup_STD,G_path + 'DataSource_Red_noDup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(HAM_DataSource_blc_STD, open(G_path + 'DataSource_60x45_Red', 'wb'))\n",
    "pickle.dump(HAM_DataSource_blc_noDup_STD, open(G_path + 'DataSource_60x45_Red_noDup', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    3450\n",
       "valid     609\n",
       "test      451\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAM_DataSource_blc_STD.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL.Image import Transpose\n",
    "\n",
    "df = pd.read_csv(\"HAM10000_metadata_processed.csv\")\n",
    "if 'Unnamed: 0' in df:\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "sizes = dict()\n",
    "labels = [5, 2, 4, 1, 0, 6, 3]\n",
    "for l in range(len(list(df[\"dx\"].value_counts()))):\n",
    "    sizes[str(labels[l])] = list(df[\"dx\"].value_counts())[l]\n",
    "print(sizes)\n",
    "cancer_indexes = [4, 1, 0] #equivalent directories: 2,3,6\n",
    "tumor_indexes = [5, 2, 6, 3] #equivalent directories: 0,1,4,5\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "folder_dir = \"dataset/\"\n",
    "\n",
    "for i in [3, 6, 5, 4]:\n",
    "    f = folder_dir + str(i) + \"/\"\n",
    "    for image in os.listdir(f):\n",
    "        if \"ISIC\" in image and image.replace(\".jpg\", \"\") in list(df[\"image_id\"]):\n",
    "            print(\"Augmented image: \", image)\n",
    "            im1 = Image.open(f + image)\n",
    "            augmented = im1.transpose(Transpose.FLIP_LEFT_RIGHT)\n",
    "            augmented = augmented.transpose(Transpose.FLIP_TOP_BOTTOM)\n",
    "            augmented.save(\"dataset_augmented/\" + str(i) + \"/AUG_\" + image)\n",
    "            im1.save(\"dataset_augmented/\" + str(i) + \"/\" + image)\n",
    "\n",
    "            values = list(df.loc[df['image_id'] == image.replace(\".jpg\", \"\")].values)[0]\n",
    "            values[0] = df[\"index\"].max() + 1\n",
    "            values[1] = \"AUG_\" + values[1]\n",
    "            values[2] = \"AUG_\" + values[2]\n",
    "\n",
    "            df_length = len(df)\n",
    "            df.loc[df_length] = values\n",
    "\n",
    "for i in [0, 2, 1]:\n",
    "    f = folder_dir + str(i) + \"/\"\n",
    "    for image in os.listdir(f):\n",
    "        if \"ISIC\" in image and image.replace(\".jpg\", \"\") in list(df[\"image_id\"]):\n",
    "            #print(image)\n",
    "            im1 = Image.open(f + image)\n",
    "            im1 = im1.save(\"dataset_augmented/\" + str(i) + \"/\" + image)\n",
    "\n",
    "\n",
    "df.to_csv(\"HAM10000_metadata_augmented.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
